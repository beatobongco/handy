<!DOCTYPE html>
<html>
<head>
  <title>Handy: read handwritten digits with AI - beatobongco.com</title>
  <meta name="description" content="A client-side neural network that tries to identify single numbers that you draw!" />
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css">
  <style type="text/css">
    .container {
      margin: 25px 75px;
    }
    canvas {
      border: 1px solid black;
      margin-right: 10px;
    }
    .noselect {
      -webkit-touch-callout: none; /* iOS Safari */
        -webkit-user-select: none; /* Safari */
         -khtml-user-select: none; /* Konqueror HTML */
           -moz-user-select: none; /* Firefox */
            -ms-user-select: none; /* Internet Explorer/Edge */
                user-select: none; /* Non-prefixed version, currently
                                      supported by Chrome and Opera */
    }
    .message-box .box{
      color: white;
      background-color: #2980b9;
      display: inline-block;
      border-radius: 5px;
      padding: 5px 10px;
    }
    .message-box .robot,
    .message-box #message {
      display: inline-block;
      vertical-align: middle;
    }
    .hidey {
      visibility: hidden;
    }
    .robot {
      font-size: 50px;
    }
    #message {
      margin-top: 8px;
      font-size: 18px;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>Handy</h1>
    <h3>What is this?</h3>
    <p>A <a href="https://www.youtube.com/watch?v=aircAruvnKk">neural network</a> that tries to identify single numbers that you draw!</p>

    <h3>Handy says...</h3>
    <div class="message-box">
      <div class="box">
        <div class="robot">ðŸ¤–</div>
        <div id="message">Loading around 5MB... This message will change when done!</div>
      </div>
    </div>
    <div class="hidey">
      <h3>Draw here!</h3>
      <p>
        The small image on the right is what's actually fed into the network.
      </p>
      <div>
        <canvas class="noselect" id="drawing-canvas" width="200" height="200"></canvas>
        <canvas class="noselect" id="resized-drawing" width="28" height="28"></canvas>
      </div>
      <div>
        <button id="clear">Clear</button>
        <button id="readDrawing">Read</button>
      </div>
      <h3>Some thoughts</h3>
      <p>This network was trained on the <a href="http://yann.lecun.com/exdb/mnist/">MNIST dataset</a>.</p>

      <p>Here are some examples of the training data:</p>

      <img src="images/0.jpg">
      <img src="images/1.jpg">
      <img src="images/2.jpg">
      <img src="images/3.jpg">
      <img src="images/4.jpg">
      <img src="images/5.jpg">
      <img src="images/6.jpg">
      <img src="images/7.jpg">
      <img src="images/8.jpg">
      <img src="images/9.jpg">

      <p>The network supposedly got a <strong>99.25%</strong> score. You'll notice however that this network seems to be performing much much worse than this. </p>

      <p>(Note: I just used the code on the <a href="https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py">keras repo</a> as my motivation was more to muck around <a href="https://js.tensorflow.org/">tensorflow.js</a>).</p>

      <p>My current intuition is this is because I haven't done the needed work to preprocess the input from the canvas like for example, trimming out whitespace or sharpening the image.</p>

      <p>This just means both the network and I have much room to improve. If you want to make sure Handy sees your digits, try filling in the whole canvas with your digit. :)</p>
    </div>
  </div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/numjs/0.16.0/numjs.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tensorflow/0.11.7/tf.min.js"></script>
<script>
  let isLoading = true

  // our keras model
  let model = null

  // tells us whether we are allowed to draw on canvas
  let paint = null

  let results = []

  // canvas vars
  let resizedCnv = document.getElementById('resized-drawing')
  let resizedCtx = resizedCnv.getContext('2d')
  let drawingCnv = document.getElementById('drawing-canvas')
  let drawingCtx = drawingCnv.getContext('2d')

  drawingCtx.fillStyle = '#000'
  resizedCtx.fillStyle = '#000'
  drawingCtx.strokeStyle = '#fff'
  drawingCtx.lineJoin = 'round'
  drawingCtx.lineWidth = 20

  // our drawing canvas' state
  let clickX = []
  let clickY = []
  let clickDrag = []

  function setMessage(msg) {
    document.getElementById('message').innerHTML = msg
  }

  function clearCanvas(ctx) {
    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height)
    ctx.fillRect(0, 0, ctx.canvas.width, ctx.canvas.height)
  }

  function predictImage(image) {
    // first, reshape the image
    // format for shape is [n_images, x_shape, y_shape, n_steps::channels?]
    // src: https://stackoverflow.com/questions/43895750/keras-input-shape-for-conv2d-and-manually-loaded-images
    reshapedImage = image.reshape([1, 28, 28, 1])

    // then create a tensor, which our model expects
    _tensor = tf.tensor(reshapedImage.selection.data, [1, 28, 28, 1])

    // gives an array of len num_classes
    model.predict(_tensor).data().then(function(predVector) {
      console.log(predVector)
      // loop over and check which is 1, that's your class
      for (var i = 0; i < predVector.length; i++) {
        if (predVector[i]) {
          results.push(i)
          setMessage('I see a ' + i + '!')
        }
      }
    })
  }

  function loadImage(src) {
    let img = new Image()
    img.src = src
    img.crossOrigin = 'Anonymous'

    img.onload = function() {
      // resize first if not correct dims
      if (this.width !== 28 || this.height !== 28) {
        clearCanvas(resizedCtx)
        resizedCtx.drawImage(img, 0, 0, 28, 28)

        loadImage(resizedCnv.toDataURL('image/jpeg'))
      } else {
        predictImage(nj.images.read(img))
      }
    }
  }

  function addClick(x, y, dragging) {
    clickX.push(x)
    clickY.push(y)
    clickDrag.push(dragging)
  }

  function redraw() {
    // clear canvas
    clearCanvas(drawingCtx)

    for (var i = 0; i < clickX.length; i++) {
      drawingCtx.beginPath()
      // dont activate on i = 0
      if (clickDrag[i] && i) {
        drawingCtx.moveTo(clickX[i - 1], clickY[i - 1])
      } else {
        drawingCtx.moveTo(clickX[i] - 1, clickY[i])
      }
      drawingCtx.lineTo(clickX[i] - 1, clickY[i])
      drawingCtx.closePath()
      drawingCtx.stroke()
    }
  }

  drawingCnv.addEventListener('mousedown', function(e) {
    var mouseX = e.pageX - this.offsetLeft
    var mouseY = e.pageY - this.offsetTop

    paint = true
    addClick(mouseX, mouseY)
    redraw()
  })

  drawingCnv.addEventListener('mousemove', function(e) {
    if (paint) {
      var mouseX = e.pageX - this.offsetLeft
      var mouseY = e.pageY - this.offsetTop
      addClick(mouseX, mouseY, true)
      redraw()
    }
  })

  drawingCnv.addEventListener('mouseleave', function(e) {
    paint = false
  })

  drawingCnv.addEventListener('mouseup', function(e) {
    paint = false
  })

  function clearAllCanvas() {
    clickX = []
    clickY = []
    clickDrag = []
    clearCanvas(drawingCtx)
    clearCanvas(resizedCtx)
  }

  document.getElementById('clear').addEventListener('click', clearAllCanvas)

  document.getElementById('readDrawing').addEventListener('click', function() {
    setMessage('Let me think...')
    loadImage(drawingCnv.toDataURL('image/png'))
  })

  tf.loadModel('https://beatobongco.com/handy/tfjs_artifacts/model.json').then(function(res) {
    model = res
    document.querySelector('.hidey').style.visibility = 'visible'
    setMessage('I have loaded! You can draw now! :)')
  })

  clearAllCanvas()
</script>
</body>
</html>
